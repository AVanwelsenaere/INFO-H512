{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42e5235-76fc-40b4-899e-76e8020a078d",
   "metadata": {},
   "source": [
    "# Scanned PDF Acquisition and Cleaning Notebook\n",
    "## How to use this notebook ?\n",
    "\n",
    "Enter the connect string and the PDF path and Run All Cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e1e4b-eb46-44f5-8fbc-4258e06ad235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECLARATIONS & CONSTANTS      #\n",
    "#################################\n",
    "\n",
    "# Requirements : \n",
    "# 1. A working installation of Tesseract with the french package ('fra').\n",
    "# 2. A working installation of Ollama with the selected model downloaded.\n",
    "# 3. A SQL Server up and running with the right database.\n",
    "\n",
    "#pip install pymupdf\n",
    "#pip install pymongo\n",
    "#pip install pdfminer.six\n",
    "#pip install pytesseract\n",
    "#pip install opencv-python\n",
    "#pip install pyspellchecker\n",
    "#pip install ollama\n",
    "\n",
    "import numpy as oNumPy\n",
    "import pandas as oPandas\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "\n",
    "_sConnectString = \"DRIVER={SQL Server};SERVER=XXX;DATABASE=Digital_Library;UID=XXX;PWD=XXX;\"\n",
    "_sPDF_Path = \"The Spiders of Great Britain and Ireland.pdf\"\n",
    "_sOllamaModel = \"deepseek-r1:8b\"     # Models : deepseek-r1:32b, deepseek-r1:8b, mistral #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518bb44-9dbe-4b07-a118-7b234fa59935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR + Data storage of a book #\n",
    "################################\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "import pyodbc\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from pdfminer.high_level import extract_text\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import ollama\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "def Display_Images(oImages):\n",
    "    for iIndex, img_base64 in enumerate(oImages):\n",
    "        img_data = base64.b64decode(img_base64)\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "        # Use of matplotlib\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Illustration {iIndex + 1}\")\n",
    "        plt.show()\n",
    "\n",
    "def Is_Text_PDF(sPDF_Path):\n",
    "    # Check is the PDF is in text or image mode.\n",
    "    sText = extract_text(sPDF_Path)\n",
    "    return len(sText.strip()) > 0\n",
    "\n",
    "def Clean_Text(sText):\n",
    "    sText = sText.replace(\"\\n\", \" \").strip()\n",
    "    return ' '.join(sText.split())\n",
    "\n",
    "def Clean_Text_Advanced(sText):   \n",
    "    if not sText:\n",
    "        return \"\"\n",
    "\n",
    "    sText = sText.replace(\"\\n\", \" \").strip()\n",
    "    sText = re.sub(r'\\s+', ' ', sText)  # Clean long spaces\n",
    "    sText = re.sub(r'[^a-zA-ZÃ€-Ã¿0-9,.!? ]+', '', sText)  \n",
    "    \n",
    "    return sText\n",
    "\n",
    "def Extract_Drawings_from_Page(oImage):\n",
    "    # A amÃ©liorer...\n",
    "    \n",
    "    gray = cv2.cvtColor(oNumPy.array(oImage), cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    drawings = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 30:  # Ignore little element\n",
    "            cropped = oImage.crop((x, y, x + w, y + h))\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            cropped.save(img_byte_arr, format=\"PNG\")\n",
    "            img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode(\"utf-8\")\n",
    "            drawings.append(img_base64)\n",
    "    return drawings\n",
    "\n",
    "def Extract_Text_and_Images_from_Page(oPage, bIsTextPDF):\n",
    "   \n",
    "    pix = oPage.get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    sOCRText = Clean_Text(pytesseract.image_to_string(img, lang=\"fra\"))\n",
    "    oImages = Extract_Drawings_from_Page(img)\n",
    "\n",
    "    if (bIsTextPDF):\n",
    "        sText = Clean_Text(oPage.get_text(\"text\"))\n",
    "    else:\n",
    "        sText = sOCRText\n",
    "    \n",
    "    return sText, sOCRText, oImages\n",
    "\n",
    "\n",
    "def Correct_Text_with_Ollama(sModel, sText, sPrompt):\n",
    "\n",
    "    if not sText or sText.strip() == \"\":\n",
    "        return sText\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(model=sModel, messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"{sPrompt} {sText}\"}\n",
    "        ])\n",
    "        \n",
    "        return response[\"message\"][\"content\"]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec Ollama : {e}\")\n",
    "        return sText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2817b7-5f4c-4247-ae3d-ecc93f19fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN PROCESS DEFINITION            #\n",
    "######################################\n",
    "\n",
    "\n",
    "def Do_Process_PDF(sPDF_Path):\n",
    "    try:\n",
    "        oDoc = fitz.open(sPDF_Path)\n",
    "        file_size = os.path.getsize(sPDF_Path) / (1024 * 1024)  # Size in Mo\n",
    "\n",
    "        print(f\"ðŸ“‚ File Size : {file_size:.2f} Mo\")\n",
    "        print(f\"ðŸ“‚ Page(s) : {len(oDoc)}\")\n",
    "        \n",
    "        sBook_Title = sPDF_Path.split('/')[-1]  # PDF Name as title.\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Books (book_title, book_date_added, book_pages_count)\n",
    "            OUTPUT INSERTED.book_id_pkey\n",
    "            VALUES (?, GETDATE(), ?)\n",
    "        \"\"\", (sBook_Title, len(oDoc)))\n",
    "        iBook_ID = cursor.fetchone()[0]\n",
    "        conn.commit()\n",
    "        \n",
    "        for iPage_Num, oPage in enumerate(oDoc):\n",
    "            dPage_Start_Time = time.time()\n",
    "            \n",
    "            print(f\"Page {iPage_Num+1} : Begin OCR and Image extraction.\")\n",
    "            \n",
    "            sText, sOCRText, oImages = Extract_Text_and_Images_from_Page(oPage, Is_Text_PDF(sPDF_Path))\n",
    "            sTextClean = Clean_Text_Advanced(sText)\n",
    "            \n",
    "            print(f\"Page {iPage_Num+1} : Begin using AI to enhance content.\")\n",
    "\n",
    "            sText_Ollama = Correct_Text_with_Ollama(_sOllamaModel, sText, \"Ce texte provient d'un OCR d'une page d'un vieux livre de biologie. Saurais tu nettoyer le rÃ©sultat pour que cela soit exploitable tout en modifiant le minimum et en conservant son sens, le tout toujours en franÃ§ais ? N'ajoute aucun autre commentaire : \")\n",
    "            sText_OllamaExp = Correct_Text_with_Ollama(_sOllamaModel, sText, \"Ce texte provient d'un OCR d'une page d'un vieux livre de biologie. Sais tu reprendre les Ã©lÃ©ments de la page et me les expliquer en conservant son sens, le tout toujours en franÃ§ais ? N'ajoute aucun autre commentaire :  \")\n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO Pages (page_book_id_fkey, page_number, page_raw_text, page_ocr_text, page_raw_text_cleaned, page_raw_text_llm, page_raw_text_llm_explain)\n",
    "                OUTPUT INSERTED.page_id_pkey\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (iBook_ID, iPage_Num + 1, sText, sOCRText, sTextClean, sText_Ollama, sText_OllamaExp))\n",
    "            page_id = cursor.fetchone()[0]\n",
    "            conn.commit()      \n",
    "\n",
    "            iImageCount = 0\n",
    "            for img_base64 in oImages:\n",
    "                img_data = base64.b64decode(img_base64)\n",
    "                cursor.execute(\"\"\"\n",
    "                       INSERT INTO Images (image_page_id_fkey, image_data, image_index)\n",
    "                       VALUES (?, ?, ?)\n",
    "                \"\"\", (page_id, img_data, iImageCount + 1))\n",
    "                iImageCount = iImageCount + 1\n",
    "            conn.commit()\n",
    "\n",
    "            PageElapsed_Time = round(time.time() - dPage_Start_Time, 3)\n",
    "            print(f\"Page {iPage_Num+1} Processed and Stored in {PageElapsed_Time} seconds (Illustrations Count : {len(oImages)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e37da-8bae-4367-8095-60adad9244ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAUNCH THE IMPORT AND CLEANING     #\n",
    "######################################\n",
    "\n",
    "start_time = time.time()\n",
    "print (\"Current Time :\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \"\\n \")\n",
    "\n",
    "# Connecting SQL Server\n",
    "conn = pyodbc.connect(_sConnectString)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "Do_Process_PDF(_sPDF_Path)\n",
    "print(\"\\nDone !\")\n",
    "\n",
    "print (\"\\nCurrent Time :\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "elapsed_time = round(time.time() - start_time, 3)\n",
    "print(f\"\\nCell execution time : {elapsed_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
