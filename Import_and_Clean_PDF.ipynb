{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a42e5235-76fc-40b4-899e-76e8020a078d",
   "metadata": {},
   "source": [
    "# Scanned PDF Acquisition and Cleaning Notebook\n",
    "## How to use this notebook ?\n",
    "\n",
    "Enter the connect string and the PDF path and Run All Cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e1e4b-eb46-44f5-8fbc-4258e06ad235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECLARATIONS & CONSTANTS      #\n",
    "#################################\n",
    "\n",
    "# Requirements : \n",
    "# 1. A working installation of Tesseract with the french package ('fra').\n",
    "# 2. A working installation of Ollama with the selected model downloaded.\n",
    "# 3. A SQL Server up and running with the right database.\n",
    "\n",
    "#pip install pymupdf\n",
    "#pip install pymongo\n",
    "#pip install pdfminer.six\n",
    "#pip install pytesseract\n",
    "#pip install opencv-python\n",
    "#pip install pyspellchecker\n",
    "#pip install ollama\n",
    "\n",
    "import numpy as oNumPy\n",
    "import pandas as oPandas\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "import pyodbc\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from pdfminer.high_level import extract_text\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import ollama\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "\n",
    "############# SOURCE PDF ############################################\n",
    "_sPDF_Path = \"Coléoptères Carabiques - Subset_Mistral.pdf\"\n",
    "#####################################################################\n",
    "\n",
    "_sSave_Mode = \"FILES\"                 # Options: \"SQL\" or \"FILES\"\n",
    "_sBase_Output_Dir = \"ExtractedBooks\"  # Root folder for file-based saving\n",
    "_bUse_OCR = True                      # Toggle usage of Tesseract\n",
    "_bUse_Ollama = True                   # Toggle usage of Ollama AI\n",
    "_sTarget_Language = \"français\"        # ou \"english\", \"dutch\", etc.\n",
    "\n",
    "\n",
    "_sConnectString = \"DRIVER={SQL Server};SERVER=XXX;DATABASE=XXX;UID=XXX;PWD=XXX;\"\n",
    "_sOllamaModel = \"mistral\"     # Models : deepseek-r1:32b, deepseek-r1:8b, mistral #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194be2f-1227-4f02-9b1a-46d9448513d6",
   "metadata": {},
   "source": [
    "# OCR & Text Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518bb44-9dbe-4b07-a118-7b234fa59935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR of a book (or PDF Document) #\n",
    "###################################\n",
    "\n",
    "def Is_Text_PDF(sPDF_Path):\n",
    "    # Check if the PDF is in text or image mode.\n",
    "    sText = extract_text(sPDF_Path)\n",
    "    return len(sText.strip()) > 0\n",
    "\n",
    "\n",
    "def Clean_Text(sText):\n",
    "    sText = sText.replace(\"\\n\", \" \").strip()\n",
    "    return ' '.join(sText.split())\n",
    "\n",
    "\n",
    "def Clean_Text_Advanced(sText):   \n",
    "    if not sText:\n",
    "        return \"\"\n",
    "\n",
    "    sText = sText.replace(\"\\n\", \" \").strip()\n",
    "    sText = re.sub(r'\\s+', ' ', sText)  # Clean long spaces\n",
    "    sText = re.sub(r'[^a-zA-ZÀ-ÿ0-9,.!? ]+', '', sText)  \n",
    "    \n",
    "    return sText\n",
    "\n",
    "\n",
    "def Correct_Text_with_Ollama(sModel, sText, sPrompt):\n",
    "\n",
    "    if not sText or sText.strip() == \"\":\n",
    "        return sText\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(model=sModel, messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"{sPrompt} {sText}\"}\n",
    "        ])\n",
    "        \n",
    "        return response[\"message\"][\"content\"]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error with Ollama : {e}\")\n",
    "        return sText\n",
    "\n",
    "\n",
    "def Extract_Drawings_from_Page(oImage):\n",
    "    # Detects and extracts illustrations from a PDF page using an improved method. \n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(oNumPy.array(oImage), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply slight blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Adaptive thresholding to better isolate illustrations\n",
    "    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Contour detection\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # List of extracted drawings\n",
    "    drawings = []\n",
    "    min_size = 5000  # Minimum size to consider an illustration\n",
    "\n",
    "    # Filter contours\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        # Ignore very small elements\n",
    "        if w * h > min_size:\n",
    "            cropped = oImage.crop((x, y, x + w, y + h))\n",
    "\n",
    "            # Convert to base64 for storage\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            cropped.save(img_byte_arr, format=\"PNG\")\n",
    "            img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode(\"utf-8\")\n",
    "            drawings.append(img_base64)\n",
    "\n",
    "    return drawings\n",
    "\n",
    "\n",
    "def Extract_Text_and_Images_from_Page(oPage, bIsTextPDF):\n",
    "    # Extracts text and illustrations from a PDF page. \n",
    "    \n",
    "    # Convert the page to an image\n",
    "    pix = oPage.get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    # OCR to retrieve the text (if necessary)\n",
    "    if _bUse_OCR:\n",
    "        sOCRText = Clean_Text(pytesseract.image_to_string(img, lang=\"fra\"))\n",
    "    else:\n",
    "        sOCRText = Clean_Text(oPage.get_text(\"text\"))\n",
    "\n",
    "    oImages = Extract_Drawings_from_Page(img)\n",
    "\n",
    "    # If it's a text-based PDF, get the text directly, otherwise use OCR\n",
    "    if bIsTextPDF:\n",
    "        sText = Clean_Text(oPage.get_text(\"text\"))\n",
    "    else:\n",
    "        sText = sOCRText\n",
    "\n",
    "    return sText, sOCRText, oImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2817b7-5f4c-4247-ae3d-ecc93f19fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN PROCESS DEFINITION            #\n",
    "######################################\n",
    "\n",
    "def Do_Process_PDF(sPDF_Path):\n",
    "    try:\n",
    "        oDoc = fitz.open(sPDF_Path)\n",
    "        file_size = os.path.getsize(sPDF_Path) / (1024 * 1024)  # Size in MB\n",
    "\n",
    "        print(f\"File Size : {file_size:.2f} MB\")\n",
    "        print(f\"Page(s) : {len(oDoc)}\")\n",
    "\n",
    "        sBook_Title = os.path.splitext(os.path.basename(sPDF_Path))[0]  # PDF Name without extension\n",
    "\n",
    "        if _sSave_Mode == \"SQL\":\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO Books (book_title, book_date_added, book_pages_count)\n",
    "                OUTPUT INSERTED.book_id_pkey\n",
    "                VALUES (?, GETDATE(), ?)\n",
    "            \"\"\", (sBook_Title, len(oDoc)))\n",
    "            iBook_ID = cursor.fetchone()[0]\n",
    "            conn.commit()\n",
    "        else:\n",
    "            output_dir = os.path.join(_sBase_Output_Dir, sBook_Title)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for iPage_Num, oPage in enumerate(oDoc):\n",
    "            dPage_Start_Time = time.time()\n",
    "\n",
    "            print(f\"Page {iPage_Num+1} : Begin OCR and Image extraction.\")\n",
    "\n",
    "            sText, sOCRText, oImages = Extract_Text_and_Images_from_Page(oPage, Is_Text_PDF(sPDF_Path))\n",
    "            sTextClean = Clean_Text_Advanced(sText)\n",
    "\n",
    "            print(f\"Page {iPage_Num+1} : Begin AI enhancement step.\")\n",
    "\n",
    "            sText_Ollama = \"\"\n",
    "            sText_OllamaExp = \"\"\n",
    "            if _bUse_Ollama:\n",
    "                prompt_clean = (\n",
    "                    f\"Ce texte provient d'un OCR d'une page d'un livre ou d'un document scientifique. \"\n",
    "                    f\"Saurais-tu nettoyer le résultat (lettres manquantes, orthographe, mots ou phrases incomplètes, etc.) \"\n",
    "                    f\"tout en modifiant le minimum et en conservant son sens, le tout toujours en {_sTarget_Language} ? \"\n",
    "                    f\"N'ajoute aucun autre commentaire :\"\n",
    "                )\n",
    "            \n",
    "                prompt_explain = (\n",
    "                    f\"Ce texte provient d'un OCR d'une page d'un livre ou d'un document scientifique. \"\n",
    "                    f\"Peux-tu reprendre les éléments de la page, les expliquer, annoter et compléter un maximum \"\n",
    "                    f\"tout en conservant le sens original, le tout toujours en {_sTarget_Language} ? \"\n",
    "                    f\"N'ajoute aucun autre commentaire :\"\n",
    "                )\n",
    "            \n",
    "                sText_Ollama = Correct_Text_with_Ollama(_sOllamaModel, sText, prompt_clean)\n",
    "                sText_OllamaExp = Correct_Text_with_Ollama(_sOllamaModel, sText, prompt_explain)\n",
    "\n",
    "            if _sSave_Mode == \"SQL\":\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO Pages (page_book_id_fkey, page_number, page_raw_text, page_ocr_text, page_raw_text_cleaned, page_raw_text_llm, page_raw_text_llm_explain)\n",
    "                    OUTPUT INSERTED.page_id_pkey\n",
    "                    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "                \"\"\", (iBook_ID, iPage_Num + 1, sText, sOCRText, sTextClean, sText_Ollama, sText_OllamaExp))\n",
    "                page_id = cursor.fetchone()[0]\n",
    "                conn.commit()\n",
    "\n",
    "                for iImageCount, img_base64 in enumerate(oImages):\n",
    "                    img_data = base64.b64decode(img_base64)\n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT INTO Images (image_page_id_fkey, image_data, image_index)\n",
    "                        VALUES (?, ?, ?)\n",
    "                    \"\"\", (page_id, img_data, iImageCount + 1))\n",
    "                conn.commit()\n",
    "            else:\n",
    "                # File saving mode\n",
    "                page_folder = os.path.join(output_dir, f\"Page_{iPage_Num+1:03d}\")\n",
    "                os.makedirs(page_folder, exist_ok=True)\n",
    "\n",
    "                with open(os.path.join(page_folder, \"raw_text.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(sText)\n",
    "                with open(os.path.join(page_folder, \"ocr_text.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(sOCRText)\n",
    "                with open(os.path.join(page_folder, \"cleaned_text.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(sTextClean)\n",
    "                if _bUse_Ollama:\n",
    "                    with open(os.path.join(page_folder, \"llm_text.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(sText_Ollama)\n",
    "                    with open(os.path.join(page_folder, \"llm_explanation.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(sText_OllamaExp)\n",
    "\n",
    "                for iImageCount, img_base64 in enumerate(oImages):\n",
    "                    img_data = base64.b64decode(img_base64)\n",
    "                    img_path = os.path.join(page_folder, f\"image_{iImageCount + 1:02d}.jpg\")\n",
    "                    with open(img_path, \"wb\") as img_file:\n",
    "                        img_file.write(img_data)\n",
    "\n",
    "            PageElapsed_Time = round(time.time() - dPage_Start_Time, 3)\n",
    "            print(f\"Page {iPage_Num+1} Processed and Stored in {PageElapsed_Time} seconds (Illustrations Count : {len(oImages)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "    finally:\n",
    "        if _sSave_Mode == \"SQL\":\n",
    "            conn.close()\n",
    "            print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a5fb8-1b96-47a2-958c-e0af7f188e9c",
   "metadata": {},
   "source": [
    "# Process launch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e37da-8bae-4367-8095-60adad9244ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAUNCH THE IMPORT AND CLEANING     #\n",
    "######################################\n",
    "\n",
    "start_time = time.time()\n",
    "print (\"Current Time :\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \"\\n \")\n",
    "\n",
    "if _sSave_Mode == \"SQL\":\n",
    "    # Connecting SQL Server\n",
    "    conn = pyodbc.connect(_sConnectString)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "Do_Process_PDF(_sPDF_Path)\n",
    "print(\"\\nDone !\")\n",
    "\n",
    "print (\"\\nCurrent Time :\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "elapsed_time = round(time.time() - start_time, 3)\n",
    "print(f\"\\nCell execution time : {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "339d49a0-8615-4fdd-8f32-e97b68126118",
   "metadata": {},
   "source": [
    "# Debug usage.\n",
    "\n",
    "def Display_Images(oImages):\n",
    "    for iIndex, img_base64 in enumerate(oImages):\n",
    "        img_data = base64.b64decode(img_base64)\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "        # Use of matplotlib\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Illustration {iIndex + 1}\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
